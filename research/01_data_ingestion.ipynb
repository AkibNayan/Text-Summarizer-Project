{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b85f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16fa0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Text-Summarizer-Project\\\\research'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e892601",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b783fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Text-Summarizer-Project'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0bf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96556f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1f811c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "537db4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from textSummarizer.logging import logger\n",
    "from textSummarizer.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4a83836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _fix_github_url(self, url):\n",
    "        \"\"\"\n",
    "        Convert GitHub blob URL to raw download URL\n",
    "        \"\"\"\n",
    "        if \"github.com\" in url and \"/blob/\" in url:\n",
    "            fixed_url = url.replace(\"github.com\", \"raw.githubusercontent.com\")\n",
    "            fixed_url = fixed_url.replace(\"/blob/\", \"/\")\n",
    "            logger.info(f\"Fixed GitHub URL: {url} -> {fixed_url}\")\n",
    "            return fixed_url\n",
    "        return url\n",
    "    \n",
    "    def _validate_zip_file(self, file_path):\n",
    "        \"\"\"\n",
    "        Validate that the file is actually a ZIP file\n",
    "        \"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        # Check file size\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        if file_size == 0:\n",
    "            raise ValueError(\"Downloaded file is empty\")\n",
    "        \n",
    "        # Check file signature\n",
    "        with open(file_path, 'rb') as f:\n",
    "            first_bytes = f.read(100)\n",
    "        \n",
    "        # Check if it's HTML (common issue with GitHub URLs)\n",
    "        if first_bytes.startswith(b'<!DOCTYPE') or first_bytes.startswith(b'<html'):\n",
    "            logger.error(\"Downloaded HTML page instead of ZIP file\")\n",
    "            # Show HTML content for debugging\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                html_content = f.read(300)\n",
    "                logger.error(f\"HTML content: {html_content}\")\n",
    "            raise ValueError(\"Downloaded HTML page instead of ZIP file. Check the URL.\")\n",
    "        \n",
    "        # Check ZIP signature\n",
    "        if not first_bytes.startswith(b'PK'):\n",
    "            raise ValueError(f\"File is not a ZIP file. First bytes: {first_bytes[:20].hex()}\")\n",
    "        \n",
    "        # Validate ZIP file structure\n",
    "        try:\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_test:\n",
    "                file_list = zip_test.namelist()\n",
    "                logger.info(f\"ZIP file is valid with {len(file_list)} files\")\n",
    "                return True\n",
    "        except zipfile.BadZipFile as e:\n",
    "            raise zipfile.BadZipFile(f\"Corrupted ZIP file: {e}\")\n",
    "    \n",
    "    def download_file(self):\n",
    "        \"\"\"\n",
    "        Download file with proper URL handling and validation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.config.local_data_file):\n",
    "                # Create directory if it doesn't exist\n",
    "                os.makedirs(os.path.dirname(self.config.local_data_file), exist_ok=True)\n",
    "                \n",
    "                # Fix GitHub URL if needed\n",
    "                download_url = self._fix_github_url(self.config.source_URL)\n",
    "                \n",
    "                logger.info(f\"Downloading from: {download_url}\")\n",
    "                \n",
    "                # Download the file\n",
    "                filename, headers = urlretrieve(\n",
    "                    url=download_url,\n",
    "                    filename=self.config.local_data_file\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"{filename} downloaded! Headers: \\n{headers}\")\n",
    "                \n",
    "                # Validate the downloaded file immediately\n",
    "                self._validate_zip_file(self.config.local_data_file)\n",
    "                logger.info(\"File validated successfully as ZIP\")\n",
    "                \n",
    "            else:\n",
    "                file_size = get_size(Path(self.config.local_data_file))\n",
    "                logger.info(f\"File already exists of size: {file_size}\")\n",
    "                \n",
    "                # Still validate existing file\n",
    "                try:\n",
    "                    self._validate_zip_file(self.config.local_data_file)\n",
    "                except (ValueError, zipfile.BadZipFile) as e:\n",
    "                    logger.warning(f\"Existing file is invalid: {e}\")\n",
    "                    logger.info(\"Removing invalid file and re-downloading...\")\n",
    "                    os.remove(self.config.local_data_file)\n",
    "                    # Recursively call to re-download\n",
    "                    return self.download_file()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # Clean up failed download\n",
    "            if os.path.exists(self.config.local_data_file):\n",
    "                os.remove(self.config.local_data_file)\n",
    "                logger.error(\"Removed failed download\")\n",
    "            \n",
    "            logger.error(f\"Download failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        Extract ZIP file with validation and error handling\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate file before extraction\n",
    "            self._validate_zip_file(self.config.local_data_file)\n",
    "            \n",
    "            unzip_path = self.config.unzip_dir\n",
    "            os.makedirs(unzip_path, exist_ok=True)\n",
    "            \n",
    "            logger.info(f\"Extracting ZIP file to: {unzip_path}\")\n",
    "            \n",
    "            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "                # Get file list\n",
    "                file_list = zip_ref.namelist()\n",
    "                logger.info(f\"Extracting {len(file_list)} files...\")\n",
    "                \n",
    "                # Extract all files\n",
    "                zip_ref.extractall(unzip_path)\n",
    "                \n",
    "                # Log some extracted files\n",
    "                if file_list:\n",
    "                    logger.info(\"Sample extracted files:\")\n",
    "                    for i, filename in enumerate(file_list[:5]):\n",
    "                        logger.info(f\"  {i+1}. {filename}\")\n",
    "                    if len(file_list) > 5:\n",
    "                        logger.info(f\"  ... and {len(file_list) - 5} more files\")\n",
    "                \n",
    "                logger.info(\"ZIP extraction completed successfully!\")\n",
    "                \n",
    "        except zipfile.BadZipFile as e:\n",
    "            logger.error(f\"ZIP file error: {e}\")\n",
    "            logger.error(\"Possible causes:\")\n",
    "            logger.error(\"1. Downloaded file is corrupted\")\n",
    "            logger.error(\"2. Wrong URL (downloaded HTML instead of ZIP)\")\n",
    "            logger.error(\"3. File is not actually a ZIP file\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Extraction failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23cdfa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-26 12:20:24,308: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-09-26 12:20:24,313: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-09-26 12:20:24,315: INFO: common: created directory at: artifacts]\n",
      "[2025-09-26 12:20:24,317: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-09-26 12:20:24,321: INFO: 2561972074: File already exists of size: ~ 179 KB]\n",
      "[2025-09-26 12:20:24,323: WARNING: 2561972074: Existing file is invalid: File is not a ZIP file. First bytes: 0a0a0a0a0a0a3c21444f43545950452068746d6c]\n",
      "[2025-09-26 12:20:24,325: INFO: 2561972074: Removing invalid file and re-downloading...]\n",
      "[2025-09-26 12:20:24,328: INFO: 2561972074: Fixed GitHub URL: https://github.com/AkibNayan/Project-Datasets/blob/main/summarizer-data.zip -> https://raw.githubusercontent.com/AkibNayan/Project-Datasets/main/summarizer-data.zip]\n",
      "[2025-09-26 12:20:24,328: INFO: 2561972074: Downloading from: https://raw.githubusercontent.com/AkibNayan/Project-Datasets/main/summarizer-data.zip]\n",
      "[2025-09-26 12:20:29,844: INFO: 2561972074: artifacts/data_ingestion/data.zip downloaded! Headers: \n",
      "Connection: close\n",
      "Content-Length: 7903594\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: application/zip\n",
      "ETag: \"dbc016a060da18070593b83afff580c9b300f0b6ea4147a7988433e04df246ca\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: 56CA:15AEE2:1C4924:23AD89:68D630A9\n",
      "Accept-Ranges: bytes\n",
      "Date: Fri, 26 Sep 2025 06:20:26 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-sin-wsss1830082-SIN\n",
      "X-Cache: MISS\n",
      "X-Cache-Hits: 0\n",
      "X-Timer: S1758867626.981211,VS0,VE527\n",
      "Vary: Authorization,Accept-Encoding\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: a98d958b1eb8a0abf49b85d78ea23be5ca578b10\n",
      "Expires: Fri, 26 Sep 2025 06:25:26 GMT\n",
      "Source-Age: 0\n",
      "\n",
      "]\n",
      "[2025-09-26 12:20:29,875: INFO: 2561972074: ZIP file is valid with 17 files]\n",
      "[2025-09-26 12:20:29,877: INFO: 2561972074: File validated successfully as ZIP]\n",
      "[2025-09-26 12:20:29,881: INFO: 2561972074: ZIP file is valid with 17 files]\n",
      "[2025-09-26 12:20:29,883: INFO: 2561972074: Extracting ZIP file to: artifacts/data_ingestion]\n",
      "[2025-09-26 12:20:29,886: INFO: 2561972074: Extracting 17 files...]\n",
      "[2025-09-26 12:20:30,120: INFO: 2561972074: Sample extracted files:]\n",
      "[2025-09-26 12:20:30,124: INFO: 2561972074:   1. samsum-test.csv]\n",
      "[2025-09-26 12:20:30,126: INFO: 2561972074:   2. samsum-train.csv]\n",
      "[2025-09-26 12:20:30,129: INFO: 2561972074:   3. samsum-validation.csv]\n",
      "[2025-09-26 12:20:30,131: INFO: 2561972074:   4. samsum_dataset/]\n",
      "[2025-09-26 12:20:30,132: INFO: 2561972074:   5. samsum_dataset/dataset_dict.json]\n",
      "[2025-09-26 12:20:30,132: INFO: 2561972074:   ... and 12 more files]\n",
      "[2025-09-26 12:20:30,132: INFO: 2561972074: ZIP extraction completed successfully!]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ceae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textSEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
